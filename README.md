## Codebase of the work : 
## HOW TO (VIRTUALLY) TRAIN YOUR SOUND SOURCE LOCALIZER 
### Authors: Prerak Srivastava, Antoine Deleforge, Archontis Politis, Emmanuel Vincent.
### Paper :  https://hal.archives-ouvertes.fr/hal-03855912/document

### ./Data generation  

Scripts for generation of room parameters, Room impulse responses and speech mixtures.

a) generate_simultor_params.py 

This script generates random simulation parameters for desired number of rooms.
Parameters corresponding to 3 real speaker localization dataset **DIRHA [1]**, **VOICEHOME2 [2]**, **STARSS22 [3]** are provided 
This script generate 4 ".yml" files : 

room_setup -> [Dimensions, absorption coeffs, surface area, volume] , 

source_setup -> [source position, Source directivity azimuth and elevation], 

receiver_setup -> [receiver position, receiver directivity azimuth and elevation] 

noise_source_setup -> [source position] File consisting of an extra source posistined in the room setup, used particularly for generating speech mixtures with variable snr's.

The script depends on params.yml file, from where the distribution of simulation parameters can be tweaked.

b) receiver_defination_DIRHA.py, receiver_defination_STARSS22, receiver_defination_VOICEHOME2

These scripts consists defination of respective arrays used in the real datasets.

When called with required parameters these script return : individual position of each mic in the room, array barrycenter , azimuth and elevation of each individual mics and the center of the 2 mic array.

Distance b/w mics are as follows 

STARSS22 : 6.8CM  

DIRHA : 30 CM

VOICEHOME2 : 10.4 CM 

c) generate_rirs.py

This script generate Room impulse responses on the basis of yaml files generated by **a)**

It uses the following version of pyroomacoustics. pyroomacousitcs  https://github.com/LCAV/pyroomacoustics/tree/dev/dirpat

d) generate_noisy_mixture.py

Creates noisy mixtures from the generated room impulse responses **c)**

 The rest of the files in this directory are utility files.

### ./retreive_real_data 

Consists scripts that retreive real data if provided with correct directory of the respective real datasets.

- get_DIRHA_data.py

- get_voice_home_data.py

- get_starss22_data.py

The output is saved in the .npz format, for easy access using numpy.

### ./train_scripts

Consists of all the scripts that are required for training the DOA system based on the generated simulated dataset. 
We used the DOA architecture presented in this paper off-the-shelf: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357962


### ./srp_phat 

SRP-PHAT scripts used as a baseline.
Can be used with simulated and real datasets [DIRHA [1], VOICEHOME2 [2] and STARSS22 [3] ]


### ./test_scripts 

Consists of all the scripts that are used for testing the DOA estimation network on simulated and real datasets.



[1] THE DIRHA-ENGLISH CORPUS AND RELATED TASKS FOR DISTANT-SPEECH RECOGNITION IN DOMESTIC ENVIRONMENTS 

https://arxiv.org/pdf/1710.02560.pdf

[2] VoiceHome-2, an extended corpus for multichannel speech processing in real homes

https://hal.inria.fr/hal-01923108/document

[3] STARSS22: A dataset of spatial recordings of real scenes with spatiotemporal annotations of sound events

https://arxiv.org/abs/2206.01948
 
